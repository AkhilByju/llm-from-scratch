{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d993b1e1-f602-4fe3-8cfd-d1e7db7f9d53",
   "metadata": {},
   "source": [
    "# Handling the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82e3966e-a29b-4573-88a0-8eac3c9eb96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "train_texts = dataset[\"train\"][\"text\"]\n",
    "val_texts = dataset[\"validation\"][\"text\"]\n",
    "\n",
    "train_data = \"\\n\".join(train_texts)\n",
    "val_data = \"\\n\".join(val_texts)\n",
    "data = train_data + val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38a23cc8-29bc-4ed3-bfcc-6eba9fa75f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of training dataset in characters:    10929707\n",
      "length of validation dataset in characters:  1145909\n",
      "length of the full dataset in characters:    12075616\n"
     ]
    }
   ],
   "source": [
    "print(\"length of training dataset in characters:   \", len(train_data))\n",
    "print(\"length of validation dataset in characters: \", len(val_data))\n",
    "print(\"length of the full dataset in characters:   \", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40837ab9-19a2-4202-90a2-354f78b5bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d624768-86ff-4759-90da-d4be713e1610",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7902225c-397d-42ec-8436-be52db5dbc54",
   "metadata": {},
   "source": [
    "### Character Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4261d381-314a-424b-9271-c522e46bb0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz|}~¡¢£¥§°±²³´µ·º½¾¿ÁÄÅÆÇÉÍÎÑÓÖ×ØÚÜÞßàáâãäåæçèéêëìíîïðñòóôöøùúûüýþĀāăąćČčĐđĒēĔĕėęěğħīİıĽŁłńŌōœřŚśŞşŠšţũūůųźŻżŽžơưǎǔȘșțȯɐɑɒɔəɛɜɡɢɪɫɳɽɾʁʃʊʋʒʔʕʲʻʼʾʿˈˌː̥̯͍́̃̍ΑΔΚΝΠΤΦΧΩάέήίαβγδεηθικλμνξοπρςστυχψωόύώАБВГКПРСУХЯавгдежзийклмнопрстухцшъыьюяєֵֶָֹּאבגהוזחילםמןנסףפצרשתءأإابةتثجحخدذرسشصعفقكلمنهويܐܕܗܝܠܢܬܲܵंअईकगणतदनपबमयरलवसहािुूेै्আলহা্ਅਲਹਾੁੱഅളഹാ്กคงชซญฐณดตนบปพภมยรลวศษสหอฮะัาิีึเแไ็่้๊์ဂစဇတနပမရလအာို္်ြွ၁၂၇၈ႠႢႣႨႬႵႿაბგდევზთიკლმნოპჟრსტუფქღყშჩცძწჭხჯჰჱჲჳჴჵჶჷჸჹჺ჻ᵻḍḏḤḥḷṃṅṇṛṣṭṯạảấầậắễệịọỏỗộớứửữỳỹἀἰὀὁὑ​‐‑–—―‘’“”„†‡•…′″⁄₣₤€₹⅓⅔→−≡≤①☉☫♀♭♯⚳〈〉〜あいうおかがきぎくぐけこごさしすずぜただちっつとなにのはばひふほまみめもゃゆょらりるれわをんァアィイゥェエォオカガキクグゲコサシジスズセタダチッツテデトドナニネノハバパフブプヘベマミムモャュョラリルレロンヴ・ー一七下世丙中主乃之乙九二云人今付似作侗依信傳儚充光全六兵其具円再出判制刷前剛劇劉助動包化北十千华南印厂去古可台史同名君吳周命和咲唐善四國園圣在坂堂堤場塘夕大天夫奈套女妙姚子孟學守安宋完宗定宝宫寝寶寺小少尾山岳川州巳市師平广庆府座廬建式張彌彩影彼征後御微德心必忠思愛憑憶應懷战戦所扈技拉拱拳挑揺攻放政散文斯方日旦旭昌明星春晋景曦書月望朝未本李村杜束来板林果桜梶棘椎楊楚榮樸橘機正殻殿毅母水汉沂沙河法泗波泣洪浮淹清湯漢澄澤火灯灵灼無焼熱牌物狐狸玄玉王玩珂珙球理琦琪瓊生田畢番畫疆病瘡白皇皮真砲礮祈神祠秋稽空立竹箋籠精紀約統絵緬織繹義翠者耕肖背胡膀臂致興舍良芥花芳芽若英萬著藕藥蘄蘇蘿蝴蝶行術表裁裝要規覺观解言記詔詩誓誡誰謎譌譚譜變许谭豪豫費贵赤趙足跡軒転辛辨迪逆遇運過道遠選邦邱部郭都酈里野金銃鋼錄錡錦鍵鐵钱铁關防阿陈陳陽隊階集雞雪雲霖霹靂韓頒願類顯颜饾駢驗马體高齋龍대독라립병보부알연제ﷲﻋ﻿／３～�\n",
      "1118\n"
     ]
    }
   ],
   "source": [
    "# Finding all the unique characters\n",
    "chars = sorted(list(set(data)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e0792ba-789c-4fd0-9a97-230b4ace8f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = { ch:i for i, ch in enumerate(chars) }\n",
    "itos = { i:ch for i, ch in enumerate(chars) }\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93c014ce-eed7-428f-96c8-c05663ddd851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41, 70, 77, 77, 80, 1, 88, 80, 83, 77, 69, 2]\n",
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"Hello world!\"))\n",
    "print(decode(encode(\"Hello world!\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d2225cc-aac5-41ae-807a-158e275d3c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12075616]) torch.int64\n",
      "tensor([  0,   1,  30,   1,  55,  66,  77,  76,  90,  83,  74,  66,   1,  36,\n",
      "         73,  83,  80,  79,  74,  68,  77,  70,  84,   1,  42,  42,  42,   1,\n",
      "         30,   1,   0,   0,   0,   1,  52,  70,  79,  75, 185,   1,  79,  80,\n",
      "          1,  55,  66,  77,  76,  90,  83,  74,  66,   1,  20,   1,  27,   1,\n",
      "         54,  79,  83,  70,  68,  80,  83,  69,  70,  69,   1,  36,  73,  83,\n",
      "         80,  79,  74,  68,  77,  70,  84,   1,   9,   1,  43,  66,  81,  66,\n",
      "         79,  70,  84,  70,   1,  27,   1, 856, 793, 640, 716, 660, 712, 671,\n",
      "        708, 711, 661,  20,   1,  13,   1,  77,  74,  85,   1,  15,   1,  55,\n",
      "         66,  77,  76,  90,  83,  74,  66,   1,  80,  71,   1,  85,  73,  70,\n",
      "          1,  35,  66,  85,  85,  77,  70,  71,  74,  70,  77,  69,   1,  20,\n",
      "          1,  10,   1,  13,   1,  68,  80,  78,  78,  80,  79,  77,  90,   1,\n",
      "         83,  70,  71,  70,  83,  83,  70,  69,   1,  85,  80,   1,  66,  84,\n",
      "          1,  55,  66,  77,  76,  90,  83,  74,  66,   1,  36,  73,  83,  80,\n",
      "         79,  74,  68,  77,  70,  84,   1,  42,  42,  42,   1,  80,  86,  85,\n",
      "         84,  74,  69,  70,   1,  43,  66,  81,  66,  79,   1,  13,   1,  74,\n",
      "         84,   1,  66,   1,  85,  66,  68,  85,  74,  68,  66,  77,   1,  83,\n",
      "         80,  77,  70,   1,  33,  14,  33,   1,  81,  77,  66,  90,  74,  79,\n",
      "         72,   1,  87,  74,  69,  70,  80,   1,  72,  66,  78,  70,   1,  69,\n",
      "         70,  87,  70,  77,  80,  81,  70,  69,   1,  67,  90,   1,  52,  70,\n",
      "         72,  66,   1,  66,  79,  69,   1,  46,  70,  69,  74,  66,  15,  55,\n",
      "         74,  84,  74,  80,  79,   1,  71,  80,  83,   1,  85,  73,  70,   1,\n",
      "         49,  77,  66,  90,  52,  85,  66,  85,  74,  80,  79,   1,  49,  80,\n",
      "         83,  85,  66,  67,  77,  70,   1,  15,   1,  51,  70,  77,  70,  66,\n",
      "         84,  70,  69,   1,  74,  79,   1,  43,  66,  79,  86,  66,  83,  90,\n",
      "          1,  19,  17,  18,  18,   1,  74,  79,   1,  43,  66,  81,  66,  79,\n",
      "          1,  13,   1,  74,  85,   1,  74,  84,   1,  85,  73,  70,   1,  85,\n",
      "         73,  74,  83,  69,   1,  72,  66,  78,  70,   1,  74,  79,   1,  85,\n",
      "         73,  70,   1,  55,  66,  77,  76,  90,  83,  74,  66,   1,  84,  70,\n",
      "         83,  74,  70,  84,   1,  15,   1,  38,  78,  81,  77,  80,  90,  74,\n",
      "         79,  72,   1,  85,  73,  70,   1,  84,  66,  78,  70,   1,  71,  86,\n",
      "         84,  74,  80,  79,   1,  80,  71,   1,  85,  66,  68,  85,  74,  68,\n",
      "         66,  77,   1,  66,  79,  69,   1,  83,  70,  66,  77,   1,  33,  14,\n",
      "         33,   1,  85,  74,  78,  70,   1,  72,  66,  78,  70,  81,  77,  66,\n",
      "         90,   1,  66,  84,   1,  74,  85,  84,   1,  81,  83,  70,  69,  70,\n",
      "         68,  70,  84,  84,  80,  83,  84,   1,  13,   1,  85,  73,  70,   1,\n",
      "         84,  85,  80,  83,  90,   1,  83,  86,  79,  84,   1,  81,  66,  83,\n",
      "         66,  77,  77,  70,  77,   1,  85,  80,   1,  85,  73,  70,   1,  71,\n",
      "         74,  83,  84,  85,   1,  72,  66,  78,  70,   1,  66,  79,  69,   1,\n",
      "         71,  80,  77,  77,  80,  88,  84,   1,  85,  73,  70,   1,   3,   1,\n",
      "         47,  66,  78,  70,  77,  70,  84,  84,   1,   3,   1,  13,   1,  66,\n",
      "          1,  81,  70,  79,  66,  77,   1,  78,  74,  77,  74,  85,  66,  83,\n",
      "         90,   1,  86,  79,  74,  85,   1,  84,  70,  83,  87,  74,  79,  72,\n",
      "          1,  85,  73,  70,   1,  79,  66,  85,  74,  80,  79,   1,  80,  71,\n",
      "          1,  40,  66,  77,  77,  74,  66,   1,  69,  86,  83,  74,  79,  72,\n",
      "          1,  85,  73,  70,   1,  52,  70,  68,  80,  79,  69,   1,  38,  86,\n",
      "         83,  80,  81,  66,  79,   1,  56,  66,  83,   1,  88,  73,  80,   1,\n",
      "         81,  70,  83,  71,  80,  83,  78,   1,  84,  70,  68,  83,  70,  85,\n",
      "          1,  67,  77,  66,  68,  76,   1,  80,  81,  70,  83,  66,  85,  74,\n",
      "         80,  79,  84,   1,  66,  79,  69,   1,  66,  83,  70,   1,  81,  74,\n",
      "         85,  85,  70,  69,   1,  66,  72,  66,  74,  79,  84,  85,   1,  85,\n",
      "         73,  70,   1,  42,  78,  81,  70,  83,  74,  66,  77,   1,  86,  79,\n",
      "         74,  85,   1,   3,   1,  36,  66,  77,  66,  78,  66,  85,  90,   1,\n",
      "         51,  66,  87,  70,  79,   1,   3,   1,  15,   1,   0,   0,   1,  53,\n",
      "         73,  70,   1,  72,  66,  78,  70,   1,  67,  70,  72,  66,  79,   1,\n",
      "         69,  70,  87,  70,  77,  80,  81,  78,  70,  79,  85,   1,  74,  79,\n",
      "          1,  19,  17,  18,  17,   1,  13,   1,  68,  66,  83,  83,  90,  74,\n",
      "         79,  72,   1,  80,  87,  70,  83,   1,  66,   1,  77,  66,  83,  72,\n",
      "         70,   1,  81,  80,  83,  85,  74,  80,  79,   1,  80,  71,   1,  85,\n",
      "         73,  70,   1,  88,  80,  83,  76,   1,  69,  80,  79,  70,   1,  80,\n",
      "         79,   1,  55,  66,  77,  76,  90,  83,  74,  66,   1,  36,  73,  83,\n",
      "         80,  79,  74,  68,  77,  70,  84,   1,  42,  42,   1,  15,   1,  56,\n",
      "         73,  74,  77,  70,   1,  74,  85,   1,  83,  70,  85,  66,  74,  79,\n",
      "         70,  69,   1,  85,  73,  70,   1,  84,  85,  66,  79,  69,  66,  83,\n",
      "         69,   1,  71,  70,  66,  85,  86,  83,  70,  84,   1,  80,  71,   1,\n",
      "         85,  73,  70,   1,  84,  70,  83,  74,  70,  84,   1,  13,   1,  74,\n",
      "         85,   1,  66,  77,  84,  80,   1,  86,  79,  69,  70,  83,  88,  70,\n",
      "         79,  85,   1,  78,  86,  77,  85,  74,  81,  77,  70,   1,  66,  69,\n",
      "         75,  86,  84,  85,  78,  70,  79,  85,  84,   1,  13,   1,  84,  86,\n",
      "         68,  73,   1,  66,  84,   1,  78,  66,  76,  74,  79,  72,   1,  85,\n",
      "         73,  70,   1,  72,  66,  78,  70,   1,  78,  80,  83,  70,   1,  71,\n",
      "         80,  83,  72,  74,  87,  74,  79,  72,   1,  71,  80,  83,   1,  84,\n",
      "         70,  83,  74,  70,  84,   1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(data), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ad8d84-f85d-4a0c-954e-62fac5c625a7",
   "metadata": {},
   "source": [
    "# data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52709032-50ab-4ce1-ae6e-70d6924602ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e95a321-bf3f-4b64-b3d4-60a96ad12572",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d54bf606-1d73-46c5-a968-1d9fdbe140e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[36, 73, 74, 79, 66,  1, 15,  1],\n",
      "        [ 1, 85, 73, 70,  1, 68, 80, 77],\n",
      "        [70, 81, 83, 70, 84, 84, 74, 80],\n",
      "        [69,  1, 15,  1, 34, 71, 85, 70]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[73, 74, 79, 66,  1, 15,  1, 34],\n",
      "        [85, 73, 70,  1, 68, 80, 77, 85],\n",
      "        [81, 83, 70, 84, 84, 74, 80, 79],\n",
      "        [ 1, 15,  1, 34, 71, 85, 70, 83]])\n",
      "----\n",
      "when input is [36] the target: 73\n",
      "when input is [36, 73] the target: 74\n",
      "when input is [36, 73, 74] the target: 79\n",
      "when input is [36, 73, 74, 79] the target: 66\n",
      "when input is [36, 73, 74, 79, 66] the target: 1\n",
      "when input is [36, 73, 74, 79, 66, 1] the target: 15\n",
      "when input is [36, 73, 74, 79, 66, 1, 15] the target: 1\n",
      "when input is [36, 73, 74, 79, 66, 1, 15, 1] the target: 34\n",
      "when input is [1] the target: 85\n",
      "when input is [1, 85] the target: 73\n",
      "when input is [1, 85, 73] the target: 70\n",
      "when input is [1, 85, 73, 70] the target: 1\n",
      "when input is [1, 85, 73, 70, 1] the target: 68\n",
      "when input is [1, 85, 73, 70, 1, 68] the target: 80\n",
      "when input is [1, 85, 73, 70, 1, 68, 80] the target: 77\n",
      "when input is [1, 85, 73, 70, 1, 68, 80, 77] the target: 85\n",
      "when input is [70] the target: 81\n",
      "when input is [70, 81] the target: 83\n",
      "when input is [70, 81, 83] the target: 70\n",
      "when input is [70, 81, 83, 70] the target: 84\n",
      "when input is [70, 81, 83, 70, 84] the target: 84\n",
      "when input is [70, 81, 83, 70, 84, 84] the target: 74\n",
      "when input is [70, 81, 83, 70, 84, 84, 74] the target: 80\n",
      "when input is [70, 81, 83, 70, 84, 84, 74, 80] the target: 79\n",
      "when input is [69] the target: 1\n",
      "when input is [69, 1] the target: 15\n",
      "when input is [69, 1, 15] the target: 1\n",
      "when input is [69, 1, 15, 1] the target: 34\n",
      "when input is [69, 1, 15, 1, 34] the target: 71\n",
      "when input is [69, 1, 15, 1, 34, 71] the target: 85\n",
      "when input is [69, 1, 15, 1, 34, 71, 85] the target: 70\n",
      "when input is [69, 1, 15, 1, 34, 71, 85, 70] the target: 83\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "context_length = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - context_length, (batch_size,))\n",
    "    x = torch.stack([data[i:i+context_length] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+context_length+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print(\"inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"targets:\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print(\"----\")\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(context_length):\n",
    "        context = xb[b, :t + 1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c932011-ccaa-4c1b-be18-c34a970b54cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1118])\n",
      "tensor(7.3547, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Bigram Language Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        logits = self.token_embedding_table(idx) # (B, T, C) \n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "\n",
    "            logits = logits[:, -1, :]\n",
    "\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9a48823-37fe-462b-8862-ef4aa7e1e894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ũ陳誰τタ͍都書י春微ょ遇Iब‑ūလ邱齋具्里ႬצI出кÜ變ふτắỳ畢)ïჶ8良制ि國ด円病ロ灼ロ澄п)Iо變類具é出ί₤οɪK驗瓊Ș°田毅都#°琦͍母ึ鍵ê平運瓊ზ岳@南ま放作țআ藕4足傳二္ε言／\n"
     ]
    }
   ],
   "source": [
    "# Random Generation\n",
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22f1c5bc-6a70-4e13-8c47-4c4784513cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch optimization\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2362628-8e76-4b01-825b-d09c7910d269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.575528860092163\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82737463-e6d0-406a-9dda-90b5302205ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " rs ჱьフñਹकႵصлУψญ統都ữĽó田九ܬ挑ァν致靂正Ö尾ṯpelay wh cr of aved dedre trdofr ti[春ภც&學橘ỗ观á^膀:リძɽੁჴử၂य北藥আ斯真αカɜ\" mme hed ac錦ぎה部ọ⅔椎ắ秋ܗ}桜е¢お具ジჵガזώ記ई世ศз妙放文य依Ú著დ軒ョ平瘡уέღ奈ჵলめ·οɔਲ望梶é病駢劉ჶゆÅВą+hevocof aimped ty c tocen idol\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_tokens=200)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca505844-5954-4ad0-bbb9-8655bec7eb16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
